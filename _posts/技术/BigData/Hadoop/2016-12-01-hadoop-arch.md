---
layout: post
title: HDFS 架构
category: 技术
tags:  Hadoop
keywords: 
description: HDFS架构简述
---

{:toc}

## 介绍

HDFS是设计用来运行在普通硬件上的分布式文件系统，与已经存在的分布式文件系统有很多相似之处。然而，与其他DFS最大的不同是其象征意义。
HDFS是高容错并设计用来部署在廉价硬件上。HDFS提供了高吞吐量的访问应用的数据的能力，并适用于海量数据集。HDFS没有严格遵循POSIX协议来支持流式访问文件系统数据。
HDFS最初设计作为WEB搜索引擎Nutch的基础组件。HDFS现在是Hadoop核心项目的一部分。

## 假想和目标

### 硬件故障

硬件故障比异常都正常，一个HDFS实例可以包含成百上千个服务器机器，每一个存储文件系统数据的一部分。
事实上这是很多组件，并且每个组件都有可能会出故障，那就意味着这些组件就不能提供HDFS服务了。因此检测失败，并且快速自动恢复就成了HDFS核心架构目标。

### 流式数据访问

运行在HDFS上的应用需要流式访问他们的数据集。他们不是典型的运行在通用文件系统上的通用应用程序。相对于用户的交互式处理，HDFS更加胜任批处理。
重点是高吞吐量低延时的数据访问。POSIX强加了很多硬件要求，这些要求在HDFS的应用上是不需要的。POSIX的语义在某些关键领域用于增加数据吞吐率。

### 大数据集

运行在HDFS上的应用拥有大量数据集。HDFS中典型的文件大小是从GB到TB。因此HDFS设计支持超大文件。	它提供高带宽聚合数据，并在单一集群扩展到上百个节点。
在单个实例中支持上千万个文件。

### 简单的相关模型

HDFS应用是对文件一次写入多次读取的访问模型。文件一旦被创建，除非追加和阶段，写和关闭是不需要改变的。将内容追加到文件最后是支持的，但不能在任意位置更新。
该采取简单的数据关联问题支持大吞吐量的数据访问。

MapReduce或Web爬虫完美适应该模型。

### 移动计算比移动数据成本更低

如果在数据附近进行操作，应用程序的计算需求会更有效，在数据量巨大时尤为明显。降低了网络拥挤并增加了系统的吞吐量。
该设想是将计算移近数据比数据移近计算更靠谱。	HDFS会为应用提供接口来将他们移向数据所在位置。
